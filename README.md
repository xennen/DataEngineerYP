# Реализованные проекты во время обучения на программе "Data engineer" Яндекс Практикум

![Python](https://img.shields.io/badge/-Python-blue)
![SQL](https://img.shields.io/badge/-SQL-pink)
![PostgreSQL](https://img.shields.io/badge/-PostgreSQL-salad)
![Docker](https://img.shields.io/badge/-Docker-blue)
![Redis](https://img.shields.io/badge/-Redis-red)
![Kafka](https://img.shields.io/badge/-Kafka-black)
![Airflow](https://img.shields.io/badge/-Airflow-orange)
![Vertica](https://img.shields.io/badge/-Vertica-grey)
![PySpark](https://img.shields.io/badge/-PySpark-green)
![Spark Streaming](https://img.shields.io/badge/-Spark_Streaming-orange)
![Yandex Cloud](https://img.shields.io/badge/-Yandex_Cloud-white)
![Kubernetes](https://img.shields.io/badge/-Kubernetes-blue)
![S3](https://img.shields.io/badge/-S3-orange)
![MongoDB](https://img.shields.io/badge/-MongoDB-yellow)
![Metabase](https://img.shields.io/badge/-Metabase-white)


**[1. Создание витрины данных для RFM-классификации пользователей агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-1)**
- построение витрин данных;
- проверка качества данных.

Использованные технологииs: **`SQL`, `PostgreSQL`**

**[2. Оптимизация модели данных интернет-магазина](https://github.com/xennen/DE/tree/main/de-project-sprint-2)**
- работа со слоями данных в хранилище; 
- работа с таблицами фактов и справочников; 
- дедупликация данных.

Использованные технологии: **`SQL`, `PostgreSQL`**

**[3. Обновление пайплайна обработки данных ](https://github.com/xennen/DE/tree/main/de-project-sprint-3)**
- построение ETL-пайплайна;
- автоматическое обновление витрин данных.

Использованные технологии: **`Python`, `Airflow`, `S3`, `PostgreSQL`, `REST API`**

**[4. Реализация витрины для расчётов выплат курьерам](https://github.com/xennen/DE/tree/main/de-project-sprint-5)**
- построение DWH;
- написание ETL-пайплайна.

Использованные технологии: **`PostgreSQL`, `Airflow`, `REST API`, `Python`, `MongoDB`**

**[5. Поиск сообществ с высокой конверсией в первое сообщение](https://github.com/xennen/DE/tree/main/de-project-sprint-6)**
- проектирование хранилища на колоночных базах данных;
- проектирование моделей хранения данных;
- проектирование ETL-пайплайнов между холодным хранилищем и колоночной базой данных.

Использованные технологии: **`S3`, `REST API`, `PostgreSQL`, `Airflow`, `Vetrica`, `Data Vault`**

**[6. Обновление хранилища данных для соцсети](https://github.com/xennen/DE/tree/main/de-project-sprint-7)**
- построение Data Lake;
- построение пайплайнов обработки данных с использованием Apache Spark.

Использованные технологии: **`Hadoop`, `MapReduce`, `HDFS`, `Apache Spark`**

**[7. Настройка потоковой обработки данных для агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-8)**
- построение системы потоковой обработки с использованием Apache Spark Structured Streaming;
- работа с брокером сообщений Kafka; 
- объединение потоковых и статических данных;
- дедупликация данных при потоковой обработке.

Использованные технологии: **`Kafka`, `Spark Streaming`, `PySpark`, `PostgreSQL`, `Python`**

**[8. Создание DWH с использованием облачных технологий для агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-9)**
- создание микросервисов;
- потоковая обработка данных;
- развёртывание инфраструктуры в Yandex Cloud.

Использованные технологии: **`Yandex Cloud`, `Kubernetes`, `Redis`, `PostgreSQL`, `Docker`, `Python`, `Kafka`, `SQL`, `DataLens`**

**[9. Реализация пайплайна обработки данных из источников и хранилище для финтех-стартапа](https://github.com/xennen/DE/tree/main/de-project-final)**
- построение ETL-пайплайна;
- построение витрин данных;
- автоматическое обновление витрин данных.

Использованные технологии: **`PostgreSQL`, `Python`, `SQL`, `Airflow`, `Vetrica`, `Metabase`**
