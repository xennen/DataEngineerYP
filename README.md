# Реализованные проекты во время обучения на программе "Data engineer" Яндекс Практикум


[1. Создание витрины данных для RFM-классификации пользователей агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-1)
- построение витрин данных;
- проверка качества данных.

*Инструменты: SQL, PostgreSQL*

[2. Оптимизация модели данных интернет-магазина](https://github.com/xennen/DE/tree/main/de-project-sprint-2)
- работа со слоями данных в хранилище; 
- работа с таблицами фактов и справочников; 
- дедупликация данных.

*Инструменты: SQL, PostgreSQL*

[3. Обновление пайплайна обработки данных ](https://github.com/xennen/DE/tree/main/de-project-sprint-3)
- построение ETL-пайплайна;
- автоматическое обновление витрин данных.

*Инструменты: Python, Airflow, S3, PostgreSQL, REST-API*

[4. Реализация витрины для расчётов выплат курьерам](https://github.com/xennen/DE/tree/main/de-project-sprint-5)
- построение DWH;
- написание ETL-пайплайна.

*Инструменты: PostgreSQL, Airflow, REST-API, Python, MongoDB*

[5. Поиск сообществ с высокой конверсией в первое сообщение](https://github.com/xennen/DE/tree/main/de-project-sprint-6)
- проектирование хранилища на колоночных базах данных;
- проектирование моделей хранения данных;
- проектирование ETL-пайплайнов между холодным хранилищем и колоночной базой данных.

*Инструменты: S3, REST-API, PostgreSQL, Airflow, Vetrica, Data Vault*

[6. Обновление хранилища данных для соцсети](https://github.com/xennen/DE/tree/main/de-project-sprint-7)
- построение Data Lake;
- построение пайплайнов обработки данных с использованием Apache Spark.

*Инструменты: Hadoop, MapReduce, HDFS, Apache Spark*

[7. Настройка потоковой обработки данных для агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-8)
- построение системы потоковой обработки с использованием Apache Spark Structured Streaming;
- работа с брокером сообщений Kafka; 
- объединение потоковых и статических данных;
- дедупликация данных при потоковой обработке.

*Инструменты: Kafka, Spark Streaming, PySpark, PostgreSQL, Python*

[8. Создание DWH с использованием облачных технологий для агрегатора доставки еды](https://github.com/xennen/DE/tree/main/de-project-sprint-9)
- создание микросервисов;
- потоковая обработка данных;
- развёртывание инфраструктуры в Yandex Cloud.

*Инструменты: Yandex Cloud, Kubernetes, Redis, PostgreSQL, Docker, Python, Kafka, SQL, DataLens*

[9. Реализация пайплайна обработки данных из источников и хранилище для финтех-стартапа](https://github.com/xennen/DE/tree/main/de-project-final)
- построение ETL-пайплайна;
- построение витрин данных;
- автоматическое обновление витрин данных.

*Инструменты: PostgreSQL, Python, SQL, Airflow, Vetrica, Metabase*
